{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5f96ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e97273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collect covid data starting from January 23rd in countries: 100%|██████████| 215/215 [01:51<00:00,  1.93it/s]\n",
      "Collect covid data starting from January 22rd in China provinces: 100%|██████████| 34/34 [00:11<00:00,  3.04it/s]\n"
     ]
    }
   ],
   "source": [
    "class CovidSpider(object):\n",
    "    def __init__(self):\n",
    "        self.home_url = 'https://ncov.dxy.cn/ncovh5/view/pneumonia'\n",
    "            \n",
    "    def get_content_from_url(self, url):\n",
    "        \"\"\"\n",
    "        obtain data according to the url response content\n",
    "        :param url:requested url\n",
    "        :return: response content\n",
    "        \"\"\"\n",
    "        # send request，obtain homepage content\n",
    "        response = requests.get(url)\n",
    "        return response.content.decode()\n",
    "    \n",
    "    def parse_home_page(self, home_page, tag_id):\n",
    "        \"\"\"\n",
    "        analyze content of home page, obtain analyzed python data \n",
    "        :param home_page:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # obtain covid data from homepage content\n",
    "        soup = BeautifulSoup(home_page, 'html5lib')\n",
    "        script = soup.find(id=tag_id)\n",
    "        text = script.text\n",
    "        # print(text)\n",
    "        \n",
    "        # obtain json string from covid data \n",
    "        json_str = re.findall(r'\\[.+\\]', text)[0]\n",
    "        # print(json_str)\n",
    "        \n",
    "        # turn json string into python data type \n",
    "        data = json.loads(json_str)\n",
    "        return data\n",
    "\n",
    "    def parse_corona_virus(self, latest_covid_China, desc):\n",
    "        # define list to store covid data \n",
    "        corona_virus = []\n",
    "        # iterate through covid data for statistical URLs\n",
    "        for country in tqdm(latest_covid_China, desc):\n",
    "            statistics_data_url = country['statisticsData']\n",
    "            statistics_data_json_str = self.get_content_from_url(statistics_data_url)\n",
    "            # analyze covid data and add them to list \n",
    "            statistics_data = json.loads(statistics_data_json_str)['data']\n",
    "            #print(statistics_data)\n",
    "            for one_day in statistics_data:\n",
    "                one_day['provinceName'] = country['provinceName']\n",
    "                if country.get('countryShortCode'):\n",
    "                    one_day['countryShortCode'] = country['countryShortCode']\n",
    "            # print(statistics_data)\n",
    "            corona_virus.extend(statistics_data)\n",
    "            # print(corona_virus)\n",
    "        return corona_virus\n",
    "\n",
    "    def load(self, path):\n",
    "        \"\"\"\n",
    "        load data according to given path\n",
    "        :param path:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        with open(path) as fp:\n",
    "            data = json.load(fp)\n",
    "        return data\n",
    "    \n",
    "    def save(self, data, path):\n",
    "        # save covid data as json file\n",
    "        with open(path, 'w') as fp:\n",
    "            json.dump(data, fp, ensure_ascii = False)\n",
    "            \n",
    "    def crawl_latest_covid(self):\n",
    "        \"\"\"\n",
    "        collect most recent date covid data from countries  \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        #1. send request，obtain homepage content\n",
    "        home_page = self.get_content_from_url(self.home_url)\n",
    "        #2. analyze homepage，obtain covid info\n",
    "        latest_covid = self.parse_home_page(home_page, tag_id='getListByCountryTypeService2true')\n",
    "        #3. save data as json file\n",
    "        self.save(latest_covid, 'data/latest_covid.json')\n",
    "        \n",
    "    def crawl_corona_virus(self):\n",
    "        \"\"\"\n",
    "         collect covid data starting from January 23rd in countries\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        #1. load coivd data from latest_covid.json\n",
    "        latest_covid = self.load('data/latest_covid.json')\n",
    "        # print(latest_covid)\n",
    "        #2. analyze homepage，obtain covid info\n",
    "        corona_virus = self.parse_corona_virus(latest_covid, desc = 'Collect covid data starting from January 23rd in countries')\n",
    "        #3. save data as json file \n",
    "        self.save(corona_virus, 'data/corona_virus.json')\n",
    "        \n",
    "    def crawl_latest_covid_china(self):\n",
    "        \"\"\"\n",
    "        collect covid data starting from January 23rd in China\n",
    "        \"\"\"\n",
    "        #1. send request，obtain homepage content\n",
    "        home_page = self.get_content_from_url(self.home_url)\n",
    "        #2. analyze homepage，obtain covid info\n",
    "        latest_covid_China = self.parse_home_page(home_page,tag_id='getAreaStat')\n",
    "        #3. save data as json file \n",
    "        self.save(latest_covid_China, 'data/latest_covid_China.json')\n",
    "        \n",
    "    def crawl_corona_virus_of_china_province(self):\n",
    "        \"\"\"\n",
    "        collect covid data starting from January 22rd in China provinces \n",
    "        \"\"\"\n",
    "        #1. load coivd data from latest_covid_China.json\n",
    "        latest_covid_China = self.load('data/latest_covid_China.json')\n",
    "        #2. analyze homepage，obtain covid info \n",
    "        corona_virus = self.parse_corona_virus(latest_covid_China, 'Collect covid data starting from January 22rd in China provinces')\n",
    "        #3. save data as json file \n",
    "        self.save(corona_virus, 'data/covid_China_province.json')\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        self.crawl_latest_covid()\n",
    "        self.crawl_corona_virus()\n",
    "        self.crawl_latest_covid_china()\n",
    "        self.crawl_corona_virus_of_china_province()\n",
    "if __name__ == '__main__':\n",
    "    spider = CovidSpider()\n",
    "    spider.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c226272",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
